{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Task 2 \u2013 Time Series Forecasting Models\n\n**Asset:** TSLA Close Price  \n**Train:** 2015-01-01 \u2192 2024-12-31  \n**Test:** 2025-01-01 \u2192 2026-01-15  \n\n### Sections\n1. Data Preparation & Train/Test Split  \n2. ARIMA / SARIMA  \n3. LSTM  \n4. Evaluation \u2013 MAE, RMSE, MAPE  \n5. Model Comparison & Discussion  \n6. Save Outputs"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Data Preparation & Train/Test Split"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# \u2500\u2500 Imports \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nfrom __future__ import annotations\n\nimport json\nimport warnings\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom sklearn.preprocessing import MinMaxScaler\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom statsmodels.tsa.arima.model import ARIMA as SmARIMA\nfrom statsmodels.tsa.stattools import adfuller\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nwarnings.filterwarnings(\"ignore\")\ntf.random.set_seed(42)\nnp.random.seed(42)\n\n# \u2500\u2500 Paths \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nNOTEBOOK_DIR = Path(\".\")\nDATA_DIR     = NOTEBOOK_DIR.parent / \"data\" / \"processed\"\nIMG_DIR      = NOTEBOOK_DIR / \"images\"\nIMG_DIR.mkdir(parents=True, exist_ok=True)\n\nTRAIN_END  = \"2024-12-31\"\nTEST_START = \"2025-01-01\"\n\nprint(\"TensorFlow:\", tf.__version__)\nprint(\"DATA_DIR exists:\", DATA_DIR.exists())\nprint(\"IMG_DIR:\", IMG_DIR.resolve())\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# \u2500\u2500 Load TSLA CSV & split \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ntsla_raw = pd.read_csv(DATA_DIR / \"TSLA_clean.csv\", header=[0, 1], index_col=0)\ntsla_raw.columns = tsla_raw.columns.get_level_values(0)\ntsla_raw = tsla_raw.dropna(how=\"all\")\ntsla_raw.index = pd.to_datetime(tsla_raw.index, errors=\"coerce\")\ntsla_raw = tsla_raw[tsla_raw.index.notna()].sort_index()\n\nclose: pd.Series = tsla_raw[\"Close\"].astype(float).dropna()\n\ntrain: pd.Series = close.loc[:TRAIN_END]\ntest:  pd.Series = close.loc[TEST_START:]\n\n# \u2500\u2500 Sanity checks \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nassert len(train) > 0, \"train is empty!\"\nassert len(test)  > 0, \"test is empty!\"\nassert train.isna().sum() == 0, f\"train has {train.isna().sum()} NaNs!\"\nassert test.isna().sum()  == 0, f\"test has {test.isna().sum()} NaNs!\"\nassert train.index.max() < test.index.min(), \"train/test overlap!\"\n\nprint(f\"Train: {train.index.min().date()} \u2192 {train.index.max().date()}  ({len(train):,} rows, NaNs={train.isna().sum()})\")\nprint(f\"Test : {test.index.min().date()} \u2192 {test.index.max().date()}   ({len(test):,} rows, NaNs={test.isna().sum()})\")\nprint(f\"Close dtype: {close.dtype}\")\nprint(close.describe())\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# \u2500\u2500 Fig 1: Train / Test split \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nfig, ax = plt.subplots(figsize=(14, 5))\nax.plot(train.index, train.values, color=\"#457B9D\", linewidth=1.2, label=\"Train (2015\u20132024)\")\nax.plot(test.index,  test.values,  color=\"#E63946\", linewidth=1.2, label=\"Test  (2025\u20132026)\")\nax.axvline(pd.Timestamp(TEST_START), color=\"black\", linestyle=\"--\", linewidth=1, label=\"Split\")\nax.set_title(\"TSLA Close Price \u2013 Train / Test Split\", fontsize=14, fontweight=\"bold\")\nax.set_xlabel(\"Date\"); ax.set_ylabel(\"Price (USD)\"); ax.legend()\nax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))\nplt.tight_layout()\nfig.savefig(IMG_DIR / \"t2_fig1_train_test_split.png\", bbox_inches=\"tight\")\nplt.show()\nprint(\"Saved t2_fig1_train_test_split.png\")\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. ARIMA / SARIMA"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# \u2500\u2500 Fig 2: ACF / PACF on first-differenced series \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ntrain_diff = train.diff().dropna()\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 4))\nplot_acf(train_diff,  lags=40, ax=axes[0], title=\"ACF  (1st diff)\")\nplot_pacf(train_diff, lags=40, ax=axes[1], title=\"PACF (1st diff)\", method=\"ywm\")\nplt.tight_layout()\nfig.savefig(IMG_DIR / \"t2_fig2_acf_pacf.png\", bbox_inches=\"tight\")\nplt.show()\nprint(\"Saved t2_fig2_acf_pacf.png\")\n\n# ADF test\nadf_stat, adf_p, *_ = adfuller(train_diff)\nprint(f\"ADF on 1st-diff: stat={adf_stat:.4f}, p={adf_p:.4f} \u2192 {'stationary' if adf_p < 0.05 else 'non-stationary'}\")\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# \u2500\u2500 Select ARIMA order via auto_arima \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nfrom pmdarima import auto_arima\n\nprint(\"Running auto_arima (may take ~1 min)...\")\n_selector = auto_arima(\n    train,\n    start_p=0, max_p=5,\n    start_q=0, max_q=5,\n    d=1,\n    seasonal=False,\n    information_criterion=\"aic\",\n    stepwise=True,\n    error_action=\"ignore\",\n    suppress_warnings=True,\n)\narima_order = _selector.order\nprint(f\"Best order: {arima_order}  AIC={_selector.aic():.2f}\")\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# \u2500\u2500 ARIMA forecast using statsmodels (avoids pmdarima predict state issues) \u2500\u2500\u2500\nprint(f\"Fitting ARIMA{arima_order} on {len(train)} training points...\")\n_sm_model  = SmARIMA(train, order=arima_order).fit()\n_fc_result = _sm_model.get_forecast(steps=len(test))\narima_forecast = pd.Series(_fc_result.predicted_mean.values, index=test.index)\n\n# \u2500\u2500 Sanity checks \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nassert len(arima_forecast) == len(test), \"forecast length mismatch!\"\nassert arima_forecast.isna().sum() == 0, f\"arima_forecast has {arima_forecast.isna().sum()} NaNs!\"\nassert (arima_forecast > 0).all(), \"arima_forecast has non-positive values!\"\n\nprint(f\"arima_forecast: shape={arima_forecast.shape}, NaNs={arima_forecast.isna().sum()}\")\nprint(arima_forecast.head())\n\n# \u2500\u2500 Fig 3: ARIMA forecast vs actuals \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nfig, ax = plt.subplots(figsize=(14, 5))\nax.plot(train.iloc[-120:].index, train.iloc[-120:].values,\n        color=\"#457B9D\", linewidth=1.2, label=\"Train (last 120 days)\")\nax.plot(test.index, test.values,\n        color=\"#2A9D8F\", linewidth=1.5, label=\"Actual\")\nax.plot(arima_forecast.index, arima_forecast.values,\n        color=\"#E63946\", linewidth=1.5, linestyle=\"--\",\n        label=f\"ARIMA{arima_order} Forecast\")\nax.set_title(\"ARIMA Forecast vs Actual \u2013 TSLA (Test Period)\", fontsize=14, fontweight=\"bold\")\nax.set_xlabel(\"Date\"); ax.set_ylabel(\"Price (USD)\"); ax.legend()\nplt.tight_layout()\nfig.savefig(IMG_DIR / \"t2_fig3_arima_forecast.png\", bbox_inches=\"tight\")\nplt.show()\nprint(\"Saved t2_fig3_arima_forecast.png\")\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. LSTM Model"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# \u2500\u2500 Scale & build sliding-window sequences \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nWINDOW = 60\n\nscaler = MinMaxScaler(feature_range=(0, 1))\ntrain_scaled = scaler.fit_transform(train.values.reshape(-1, 1))\n\nX_train, y_train = [], []\nfor i in range(WINDOW, len(train_scaled)):\n    X_train.append(train_scaled[i - WINDOW:i, 0])\n    y_train.append(train_scaled[i, 0])\n\nX_train = np.array(X_train).reshape(-1, WINDOW, 1)\ny_train = np.array(y_train)\n\nprint(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\nassert not np.isnan(X_train).any(), \"X_train has NaNs!\"\nassert not np.isnan(y_train).any(), \"y_train has NaNs!\"\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# \u2500\u2500 LSTM architecture \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nmodel = Sequential([\n    LSTM(64, return_sequences=True, input_shape=(WINDOW, 1)),\n    Dropout(0.2),\n    LSTM(32, return_sequences=False),\n    Dropout(0.2),\n    Dense(1),\n])\nmodel.compile(optimizer=\"adam\", loss=\"mse\")\nmodel.summary()\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# \u2500\u2500 Train \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nearly_stop = EarlyStopping(monitor=\"val_loss\", patience=8, restore_best_weights=True)\n\nhistory = model.fit(\n    X_train, y_train,\n    epochs=50,\n    batch_size=32,\n    validation_split=0.1,\n    callbacks=[early_stop],\n    verbose=1,\n)\n\n# \u2500\u2500 Fig 4: training loss \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nfig, ax = plt.subplots(figsize=(10, 4))\nax.plot(history.history[\"loss\"],     label=\"Train Loss\")\nax.plot(history.history[\"val_loss\"], label=\"Val Loss\")\nax.set_title(\"LSTM Training Loss\", fontsize=13, fontweight=\"bold\")\nax.set_xlabel(\"Epoch\"); ax.set_ylabel(\"MSE\"); ax.legend()\nplt.tight_layout()\nfig.savefig(IMG_DIR / \"t2_fig4_lstm_loss.png\", bbox_inches=\"tight\")\nplt.show()\nprint(\"Saved t2_fig4_lstm_loss.png\")\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# \u2500\u2500 LSTM forecast over test period \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ncombined        = pd.concat([train, test])\ncombined_scaled = scaler.transform(combined.values.reshape(-1, 1))\n\nX_test = []\nstart  = len(train) - WINDOW\nfor i in range(start, start + len(test)):\n    X_test.append(combined_scaled[i:i + WINDOW, 0])\n\nX_test = np.array(X_test).reshape(-1, WINDOW, 1)\nassert X_test.shape[0] == len(test), f\"X_test rows {X_test.shape[0]} != test len {len(test)}\"\nassert not np.isnan(X_test).any(), \"X_test has NaNs!\"\n\nlstm_pred_scaled = model.predict(X_test, verbose=0)\nlstm_pred_values = scaler.inverse_transform(lstm_pred_scaled).flatten()\nlstm_forecast    = pd.Series(lstm_pred_values, index=test.index)\n\n# \u2500\u2500 Sanity checks \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nassert len(lstm_forecast) == len(test), \"lstm_forecast length mismatch!\"\nassert lstm_forecast.isna().sum() == 0, f\"lstm_forecast has {lstm_forecast.isna().sum()} NaNs!\"\n\nprint(f\"lstm_forecast: shape={lstm_forecast.shape}, NaNs={lstm_forecast.isna().sum()}\")\nprint(lstm_forecast.head())\n\n# \u2500\u2500 Fig 5: LSTM forecast vs actuals \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nfig, ax = plt.subplots(figsize=(14, 5))\nax.plot(train.iloc[-120:].index, train.iloc[-120:].values,\n        color=\"#457B9D\", linewidth=1.2, label=\"Train (last 120 days)\")\nax.plot(test.index, test.values,\n        color=\"#2A9D8F\", linewidth=1.5, label=\"Actual\")\nax.plot(lstm_forecast.index, lstm_forecast.values,\n        color=\"#F4A261\", linewidth=1.5, linestyle=\"--\", label=\"LSTM Forecast\")\nax.set_title(\"LSTM Forecast vs Actual \u2013 TSLA (Test Period)\", fontsize=14, fontweight=\"bold\")\nax.set_xlabel(\"Date\"); ax.set_ylabel(\"Price (USD)\"); ax.legend()\nplt.tight_layout()\nfig.savefig(IMG_DIR / \"t2_fig5_lstm_forecast.png\", bbox_inches=\"tight\")\nplt.show()\nprint(\"Saved t2_fig5_lstm_forecast.png\")\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Evaluation \u2013 MAE, RMSE, MAPE"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# \u2500\u2500 Pre-evaluation sanity checks \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nprint(\"=== Pre-evaluation sanity checks ===\")\nprint(f\"test           shape={test.shape},           NaNs={test.isna().sum()}\")\nprint(f\"arima_forecast shape={arima_forecast.shape}, NaNs={arima_forecast.isna().sum()}\")\nprint(f\"lstm_forecast  shape={lstm_forecast.shape},  NaNs={lstm_forecast.isna().sum()}\")\n\nfor name, arr in [(\"test\", test), (\"arima_forecast\", arima_forecast), (\"lstm_forecast\", lstm_forecast)]:\n    assert arr.isna().sum() == 0, f\"{name} still has NaNs \u2014 re-run its cell!\"\n    assert len(arr) > 0,          f\"{name} is empty!\"\nprint(\"All checks passed \u2713\")\n\n# \u2500\u2500 Metric helpers \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndef mape(actual: np.ndarray, predicted: np.ndarray) -> float:\n    mask = actual != 0\n    return float(np.mean(np.abs((actual[mask] - predicted[mask]) / actual[mask])) * 100)\n\ndef evaluate(name: str, actual: np.ndarray, predicted: np.ndarray) -> dict:\n    a = np.array(actual,    dtype=float)\n    p = np.array(predicted, dtype=float)\n    assert len(a) == len(p), f\"{name}: length mismatch {len(a)} vs {len(p)}\"\n    assert not np.isnan(a).any(), f\"{name}: actual has NaNs\"\n    assert not np.isnan(p).any(), f\"{name}: predicted has NaNs\"\n    mae      = float(mean_absolute_error(a, p))\n    rmse     = float(np.sqrt(mean_squared_error(a, p)))\n    mape_val = mape(a, p)\n    print(f\"  {name:<16}  MAE={mae:>8.2f}  RMSE={rmse:>8.2f}  MAPE={mape_val:>6.2f}%\")\n    return {\"model\": name, \"MAE\": round(mae, 4), \"RMSE\": round(rmse, 4), \"MAPE\": round(mape_val, 4)}\n\nprint(f\"\\n{'Model':<16}  {'MAE':>10}  {'RMSE':>10}  {'MAPE':>8}\")\nprint(\"-\" * 54)\narima_metrics = evaluate(f\"ARIMA{arima_order}\", test.values, arima_forecast.values)\nlstm_metrics  = evaluate(\"LSTM\",               test.values, lstm_forecast.values)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. Model Comparison & Discussion"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \u2500\u2500 Fig 6: side-by-side forecast comparison \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "metrics_df = pd.DataFrame([arima_metrics, lstm_metrics]).set_index(\"model\")\n",
    "print(\"\\nModel Comparison Table\")\n",
    "print(\"=\" * 45)\n",
    "print(metrics_df.to_string())\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5), sharey=True)\n",
    "for ax, forecast, label, color in zip(\n",
    "    axes,\n",
    "    [arima_forecast, lstm_forecast],\n",
    "    [f\"ARIMA{arima_order}\", \"LSTM\"],\n",
    "    [\"#E63946\", \"#F4A261\"],\n",
    "):\n",
    "    ax.plot(test.index, test.values,     color=\"#2A9D8F\", linewidth=1.5, label=\"Actual\")\n",
    "    ax.plot(test.index, forecast.values, color=color,     linewidth=1.5,\n",
    "            linestyle=\"--\", label=label)\n",
    "    ax.set_title(f\"{label} vs Actual\", fontsize=13, fontweight=\"bold\")\n",
    "    ax.set_xlabel(\"Date\"); ax.set_ylabel(\"Price (USD)\"); ax.legend()\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%b %Y\"))\n",
    "    plt.setp(ax.xaxis.get_majorticklabels(), rotation=30)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(IMG_DIR / \"t2_fig6_model_comparison.png\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(\"Saved t2_fig6_model_comparison.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Discussion\n\n**ARIMA** is a classical statistical model that assumes linearity and stationarity.\nAfter first-differencing (d=1), it captures autocorrelation structure well for short horizons.\nHowever, it cannot model non-linear patterns or long-range dependencies in volatile assets like TSLA.\n\n**LSTM** is a recurrent neural network that learns non-linear temporal patterns from a sliding window\nof past prices. It typically outperforms ARIMA on volatile financial series over longer test horizons,\nat the cost of longer training time and more hyperparameter tuning.\n\nThe model with lower RMSE on the test set is recommended for Task 3 future forecasting."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6. Save Outputs"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# \u2500\u2500 Save forecast CSVs \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\narima_forecast.to_csv(DATA_DIR / \"arima_forecast.csv\", header=[\"arima_forecast\"])\nlstm_forecast.to_csv( DATA_DIR / \"lstm_forecast.csv\",  header=[\"lstm_forecast\"])\nprint(\"Saved arima_forecast.csv\")\nprint(\"Saved lstm_forecast.csv\")\n\n# \u2500\u2500 Save stats JSON \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nbest_model = min([arima_metrics, lstm_metrics], key=lambda x: x[\"RMSE\"])[\"model\"]\nstats = {\n    \"arima_order\":       list(arima_order),\n    \"lstm_window\":       WINDOW,\n    \"metrics\":           {m[\"model\"]: {k: v for k, v in m.items() if k != \"model\"}\n                          for m in [arima_metrics, lstm_metrics]},\n    \"best_model_by_rmse\": best_model,\n}\nwith open(DATA_DIR / \"task2_stats.json\", \"w\") as f:\n    json.dump(stats, f, indent=2)\nprint(f\"Saved task2_stats.json  (best model: {best_model})\")\nprint(json.dumps(stats, indent=2))\n"
  }
 ]
}